{
  "hash": "6be3aa640987c42e05f93a5777c87bdc",
  "result": {
    "markdown": "# Statistical simulation and limit theorems\n\n> For us, there are two reasons to learn about stochastic simulation. The first is that for complex systems, simulation can be an alternative to mathematical analysis, sometimes the only one. The second reason is that through simulation, we can get more feeling for random variables, and this is why we study stochastic simulation at this point in the book. (Dekking et al., p. 72)\n\n## Curriculum\n\n### Core readings\n\n1.  Dekking et al., Chapter 13: The law of large numbers\n\n2.  Dekking et al., Chapter 14: The central limit theorem\n\n3. The notes below.\n\n4. (*Optional*)Dekking et al., Chapter 6: Simulations. Except Chapter 6.4 The single-server queue.\n\n### Random number generators\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport numpy as np\nimport scipy as sp\n```\n:::\n\n\nWe start by defining an random number generator (*rng*). Computers do not usually generate truly random numbers. Instead they generate so-called [pseudo-random numbers](https://en.wikipedia.org/wiki/Pseudorandom_number_generator) using methods such as the [linear congruential generator](https://en.wikipedia.org/wiki/Linear_congruential_generator). (It is possible to generate truly random numbers using the [`RDRAND` instruction](https://en.wikipedia.org/wiki/RDRAND) on x64 processors, but this feature is almost never used for various reasons.)\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nrng = np.random.default_rng(seed = 313)\nrng\n```\n\n::: {.cell-output .cell-output-display execution_count=37}\n```\nGenerator(PCG64) at 0x14BFA36FCA0\n```\n:::\n:::\n\n\nAs you can see, the object `rng` is a `Generator(PCG64)`, i.e., a random number generator.\n\nGenerator objects have methods, such as `uniform` and `normal`, that may be used to generate random values.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nrng.uniform(0, 1, size = 10)\n```\n\n::: {.cell-output .cell-output-display execution_count=38}\n```\narray([0.63182242, 0.46427464, 0.77927765, 0.40253182, 0.61196237,\n       0.32392294, 0.10567386, 0.68671495, 0.01786417, 0.60813899])\n```\n:::\n:::\n\n\nThis code generates a column vector of ten elements randomly sampled from the uniform distribution on $[0,1]$. The `size` argument is a Numpy dimension, hence you can write:\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nrng.uniform(0, 1, size = (2, 10))\n```\n\n::: {.cell-output .cell-output-display execution_count=39}\n```\narray([[0.77322932, 0.23260444, 0.56660324, 0.96823875, 0.93026402,\n        0.71578432, 0.29358623, 0.53439132, 0.81535993, 0.42267216],\n       [0.96857697, 0.96626312, 0.24506702, 0.44363894, 0.45995697,\n        0.86179148, 0.45618709, 0.90139015, 0.51322552, 0.93442797]])\n```\n:::\n:::\n\n\nThis is an array with $2$ rows and $10$ columns.\n\nOur generator `rng` was defined using the argument `seed = 313`. This is used for *reproducibility*. If you run the same code twice with the same seed, the result is going to be the same.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nrng1 = np.random.default_rng(seed = 313)\nrng2 = np.random.default_rng(seed = 313)\n(rng1.uniform(0, 1, size = (2, 2)), rng2.uniform(0, 1, size = (2, 2)))\n```\n\n::: {.cell-output .cell-output-display execution_count=40}\n```\n(array([[0.63182242, 0.46427464],\n        [0.77927765, 0.40253182]]),\n array([[0.63182242, 0.46427464],\n        [0.77927765, 0.40253182]]))\n```\n:::\n:::\n\n\nBut the results will not be the same if we do not provide the seed!\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nrng1 = np.random.default_rng()\nrng2 = np.random.default_rng()\n(rng1.uniform(0, 1, size = (2, 2)), rng2.uniform(0, 1, size = (2, 2)))\n```\n\n::: {.cell-output .cell-output-display execution_count=41}\n```\n(array([[0.7517041 , 0.14098333],\n        [0.43197008, 0.90082144]]),\n array([[0.97025446, 0.64707406],\n        [0.68077437, 0.59009093]]))\n```\n:::\n:::\n\n\nReproducibility is important in scientific applications, as the reader of your work can exactly reproduce your simulations on his own computer. It's also relevant for our coursework, as it allows your teacher to automatically grade your submissions.\n\nThe first two arguments of `rng.uniform` specify the start point and end point of the interval we sample from.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nrng1 = np.random.default_rng(seed = 313)\nrng2 = np.random.default_rng(seed = 313)\nx = rng1.uniform(2, 5, size = (2, 2)) # starting at 2 and ending at 5,\ny = rng2.uniform(0, 1, size = (2, 2)) # starting at 0 and ending at 1.\n\n(x, 3*y + 2)\n```\n\n::: {.cell-output .cell-output-display execution_count=42}\n```\n(array([[3.89546727, 3.39282392],\n        [4.33783294, 3.20759547]]),\n array([[3.89546727, 3.39282392],\n        [4.33783294, 3.20759547]]))\n```\n:::\n:::\n\n\nNow $x$ and $y$ are the same. This will always be the case.\n\n#### Quick exercise\n\nGenerate an array of uniformly distributed numbers on $[1,5]$ with $3$ rows and $4$ columns.\n\n::: {.callout-tip collapse=\"true\"}\n##### Solution\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nx = rng1.uniform(2, 5, size = (3, 4))\nx\n```\n\n::: {.cell-output .cell-output-display execution_count=43}\n```\narray([[3.8358871 , 2.97176881, 2.31702157, 4.06014485],\n       [2.05359251, 3.82441698, 4.31968797, 2.69781331],\n       [3.69980971, 4.90471626, 4.79079206, 4.14735295]])\n```\n:::\n:::\n\n\n:::\n\n\n### Using distributions\n\nYou can generate normally distributed random values with mean `mu` and standard deviation `sigma` using `rng.normal(mu, sigma, size)`. Again, the `size` argument tells `numpy` how many rows, columns and potentially more dimensions you want your array to have.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nx = rng1.normal(0, 1, 10000)\n```\n:::\n\n\nLet's verify that `x` is normally distributed by plotting its histogram.\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.histplot(x, stat = \"density\")\nplt.show()\nplt.clf()\n```\n\n::: {.cell-output .cell-output-display}\n![](02-statistical-simulation_files/figure-html/cell-11-output-1.png){width=597 height=411}\n:::\n\n::: {.cell-output .cell-output-display}\n```\n<Figure size 672x480 with 0 Axes>\n```\n:::\n:::\n\n\nRecall the formula for the density of the normal distribution,\n$$f(x;\\mu,\\sigma) = \\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp{\\lbrack-\\frac{1}{2}(x-\\mu)^2}\\rbrack.$$\nTo verify that the histogram is normal, we can overlay the density of a normal on top of it. \n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\ny = np.linspace(-5, 5, 1000)\ndef normpdf(x, mu = 0, sigma = 1):\n  return np.exp(-(x - mu) ** 2 * 0.5) * 1/(np.sqrt(2 * np.pi) * sigma)\n\nsns.histplot(x, stat = \"density\")\nplt.plot(y, normpdf(y), color = \"red\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](02-statistical-simulation_files/figure-html/cell-12-output-1.png){width=597 height=411}\n:::\n:::\n\n\nThe `Generator` object supports random sampling from many other distributions too. See [the documenation](https://numpy.org/doc/stable/reference/random/generator.html#distributions) for a complete list. The examples below are especially important.\n\n| Function   | Distribution | \n| --------   | ------------ |\n| `integers` | Random integers from low (inclusive) to high (exclusive).\n| `choice`   | Sample from an array with or without replacement.\n| `uniform`  | Uniformly distributed numbers.\n| `random`   | Uniformly distributed numbers on `[0,1]`.\n| `normal`   | Normally distributed numbers.\n| `standard_normal` | Normally distributed numbers with mean 0 and standard deviation 1.\n| `exponential` | Exponentially distributed numbers with scale parameter.\n| `standard_exponential` | Exponentially distributed numbers with scale parameter 1.\n\n#### Quick exercise\n\nSimulate $10,000$ random variables from a standard exponential. Verify that the random variables were simulated from an exponential by overlaying the standard exponential density.\n\n::: {.callout-tip collapse=\"true\"}\n##### Solution\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nx = rng1.standard_exponential(10000)\ny = np.linspace(0, 6, 1000)\nsns.histplot(x, stat = \"density\")\nplt.plot(y, np.exp(-y), color = \"red\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](02-statistical-simulation_files/figure-html/cell-13-output-1.png){width=589 height=411}\n:::\n:::\n\n\n:::\n\n### Simulating dice throws\n\nRandom number generators are often used to calculate probabilities that are hard to calculate by hand. You might be able to calculate, say, what he probability of getting a sum equal to $7$ is when throwing $2$ dice. But what about the probability that the maximal value $6$ or that the sum is $7$? This is also doable by hand, but it's easier to do it by machine.\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nrng = np.random.default_rng(seed = 313)\nthrows = rng.integers(1, 7, size = (10000, 2))\n# throws contaisn 10000 rows of two dice throws.\ntotals = throws.sum(axis = 1)\nmaxs = throws.max(axis = 1)\n(totals, maxs)\n```\n\n::: {.cell-output .cell-output-display execution_count=48}\n```\n(array([6, 5, 6, ..., 9, 8, 9], dtype=int64),\n array([4, 3, 5, ..., 6, 5, 6], dtype=int64))\n```\n:::\n:::\n\n\nTo calculate our probability, we need either `totals == 7` or `maxs == 6`. We can use vectorized \"OR\" using the Numpy function `logical_or` to calculate this.\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nx = np.logical_or(totals == 7, maxs == 6)\nx\n```\n\n::: {.cell-output .cell-output-display execution_count=49}\n```\narray([False, False, False, ...,  True, False,  True])\n```\n:::\n:::\n\n\nThen we can take their mean to figure out the probability.\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nx.mean()\n```\n\n::: {.cell-output .cell-output-display execution_count=50}\n```\n0.4134\n```\n:::\n:::\n\n\nThus the probability is approximately $0.41$. (Observe that Numpy automatically interprets `True` as `1` and `False` as `0` when forced to interpret boolean values as integers.)\n\nIn practice, we would write all of this in one go, probably using a function.\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\ndef prob(rng, n_reps = 10000):\n  throws = rng.integers(1, 7, size = (10000, 2))\n  return np.logical_or(throws.sum(axis = 1) == 7, throws.max(axis = 1) == 6).mean()\n  \nprob(rng)\n```\n\n::: {.cell-output .cell-output-display execution_count=51}\n```\n0.422\n```\n:::\n:::\n\n\nThe result of this simulation is slightly different from the last one. This is due to randomnes, pure and simple. As we have already generated values from our `rng`, we would have to reset it to get the same value as before.\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nrng = np.random.default_rng(seed = 313)\nprob(rng)\n```\n\n::: {.cell-output .cell-output-display execution_count=52}\n```\n0.4134\n```\n:::\n:::\n\n\n### Complex simulation\nSuppose that $X_1,X_2,\\ldots,X_k$ are $k$ iid exponential variables with density $\\lambda e^{-\\lambda x}, \\lambda > 0$. It has been claimed that the minimum of $k$ such variables are exponentially distributed with parameter $k \\lambda$, i.e., $\\min(X_1,X_2,\\ldots,X_k)$ has density $\\lambda k e^{-\\lambda k x}$. Let's try to verify this using simulations.\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\nrng = np.random.default_rng(seed = 313)\n```\n:::\n\n\n## Exercises\n\n## Additional resources\n\n",
    "supporting": [
      "02-statistical-simulation_files"
    ],
    "filters": [],
    "includes": {}
  }
}