{
  "hash": "5156b0bd84de74da2deadcf28b36b835",
  "result": {
    "markdown": "# Introduction to `Numpy`\n\nIn this course we'll several external Python libraries. If you have trouble installing Python locally, you can always use [Google Colab](https://colab.research.google.com).\n\n1. `Numpy`, the fundamental package for scientific computing with Python. Numpy does all the heavy mathematical lifiting, such as matrix multiplication and summing. We use Numpy due to its *speed* and *convenience*. The syntax of Numpy is very similar to that of [TensorFlow](https://www.tensorflow.org), which is used extensively in heavy-duty machine learning applications.\n2. `Pandas` deals with data frames. Most of our data will be on the Pandas format. \n3. `statsmodels`. Statsmodels is the Python package for basic statistical analysis in Python. It closely mimics `R` in syntax and functionality.\n4. `scikit-learn` is somewhat similar to statsmodels, but contains much more functionality and is geared towards [machine learning instead of statistics](https://towardsdatascience.com/the-actual-difference-between-statistics-and-machine-learning-64b49f07ea3). \n5. `matplotlib`, the basic plotting library in Python.\n6. `seaborn`. A package that simplifies plotting. \n7. `tinybench`. Used for doing benchmarks, i.e., timing how long functions take to run. You can learn a lot about how to write efficient code by routinely using this package while coding. It's also quite fun - optimizing code is one of the pleasures of programming, and `tinybench` makes it easy to check if any of your optimizations make sense.\n\n## Curriculum\n\n1. [Numpy for absolute beginners](https://numpy.org/doc/stable/user/absolute_beginners.html)\n2. The notes on this webpage.\n\n### Numpy\nI sometimes write that you should *familiarize yourself with* the documentation. This means that you should: \n1. Fire up an instance of [Visual Studio Code](https://code.visualstudio.com) (recommended), Jupyter Notebook, or your prefered way to write Python.\n2. Go to the supplied links and *actively* read them. You can't just print out the documents and read them in the shade of a tree. You should make an hypothesis about how a snippet of code works, copy the Python code to your editor, and then modify it to check if your hypothesis is true.\n\n### The speed of `Numpy`\n\nPython is very slow language. So slow, in fact, that most optimizations in Python is about moving as many computations as possible to Numpy.\n\nThe following function sums up all numbers from $1..n$ in vanilla Python.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\ndef sum_python(n):\n  numbers = range(0, n)\n  acc = 0\n  for i in numbers:\n    acc = acc + i\n  return acc\n```\n:::\n\n\nThe function below uses Numpy for the same task.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport numpy as np\ndef sum_numpy(n):\n  numbers = np.arange(0, n, dtype = np.int64)\n  return numbers.sum()\n\n```\n:::\n\n\nBoth functions return the same value.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nsum_python(10 ** 6)\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n499999500000\n```\n:::\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nsum_numpy(10 ** 6)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n499999500000\n```\n:::\n:::\n\n\nThe Numpy code is arguably easier to read. There is no doubt what the `.sum` method does. \n\nWe use the `dtype = np.int64` argument in the `np.arange` function. This makes `int64` the data type of the resulting Numpy array. These are 64 bits (signed) integers, but the standard is 32 bits integer. The difference between these lie in their maximum and minimum values. The maximal value of a 64 bits integer is `9,223,372,036,854,775,807`, but the maximal value of an `i32` is merely `2,147,483,647`. You have to manually specify `i64` when dealing with big integers in Numpy, but you do not need to do that in Python, as it can use integers of arbitrary size, at the cost of speed. You can always find the data type of a Numpy object using the `.dtype` method, e.g.,\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nx = np.arange(0, 10)\nx.dtype\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\ndtype('int32')\n```\n:::\n:::\n\n\nWe compare the execution speed of these functions using the `benchmark` function from the `tinybench` package. As always, type `help(benchmark)` in a Python interpreter to get help for the function. Below, we sample `ntimes = 10` and use a warm up of `10` (to get the processor running). The `g` argument tells `benchmark` where to find the functions in the list, and the argument `globals()` tells it to look at the top level.  \n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nfrom tinybench import benchmark, benchmark_env\nbench = benchmark(['sum_python(10 ** 6)', 'sum_numpy(10 ** 6)'], ntimes = 100, warmup = 10, g = globals())\nbench.plot()\n```\n\n::: {.cell-output .cell-output-display}\n![](01-scipy-numpy_files/figure-html/cell-7-output-1.png){width=662 height=470}\n:::\n:::\n\n\nThe Numpy version is much faster. To pinpoint by exactly how much, we need to look at the mean execution times.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nbench.means\nbench.means['sum_python'] / bench.means['sum_numpy']\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\n10.571063624202676\n```\n:::\n:::\n\n\nThe Numpy implementation is roughly $10$ times faster. One can expect speedups even larger than this in more complex applications.\n\n## Exercises\n\n### Data types\n\n#### Exercise 1\nFigure out the answer the following questions, using e.g. the Numpy documentation. (Look up the functions `iinfo`).\n\n1. What is the minimal value of a 32 bit integer in Numpy? \n2. What is the minimal value of a 64 bit integer in Numpy?\n3. Is there an integer type even larger than `int64`, provided you restrict yourself to non-negative numbers, i.e., *unsigned* integers?\n\n\n::: {.callout-tip collapse=\"true\"}\n## Solution\nThe first two questions can be answered by \n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nnp.iinfo(np.int32)\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\niinfo(min=-2147483648, max=2147483647, dtype=int32)\n```\n:::\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nnp.iinfo(np.int64)\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\niinfo(min=-9223372036854775808, max=9223372036854775807, dtype=int64)\n```\n:::\n:::\n\n\nFor the last question: Yes, the unsigned integers `uint64` are larger.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nnp.iinfo(np.uint64)\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\niinfo(min=0, max=18446744073709551615, dtype=uint64)\n```\n:::\n:::\n\n\n:::\n\n#### Exercise 2\nDecimal numbers in computer science are called *floats*, or floating point numbers. (Look up the functions `finfo`).\n\n1. What types of floats are available in Numpy?\n2. What is the default float type when using `linspace`?\n3. What are the maximal and minimal values of these float types?\n\n::: {.callout-tip collapse=\"true\"}\n## Solution\n1. We have `np.float16`, `np.float32` and `np.float64`.\n2. Using `np.linspace(0, 1, 4).dtype` we find that `float64` is the default data type.\n3. We can read that from the results below:\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nnp.finfo(np.float64)\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\nfinfo(resolution=1e-15, min=-1.7976931348623157e+308, max=1.7976931348623157e+308, dtype=float64)\n```\n:::\n:::\n\n\n:::\n\n### Benchmarking and Numpy\n\n#### Exercise 1\nPython implements a method `sum` that sums every member of an *iterable* such as list. Implement a function `sum_python2` that uses `sum` instead of a for-loop, but does not use Numpy. Compare its performance to `sum_python` above. What do you see?\n\n::: {.callout-tip collapse=\"true\"}\n## Solution\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\ndef sum_python2(n):\n  numbers = range(0, n)\n  return sum(numbers)\n\nfrom tinybench import benchmark, benchmark_env\nbench = benchmark(['sum_python(10 ** 6)', 'sum_python2(10 ** 6)', 'sum_numpy(10 ** 6)'], ntimes = 100, warmup = 10, g = globals())\nbench.plot()  \n```\n\n::: {.cell-output .cell-output-display}\n![](01-scipy-numpy_files/figure-html/cell-13-output-1.png){width=661 height=470}\n:::\n:::\n\n\n:::\n\n\n#### Exercise 2\nWrite a function that squares and sums the numbers from `1` to `n`, one in Numpy and one in pure Python. Roughly how much faster is the Numpy implementation than the Python implementation when using `n=1000`, `n=10000`, or `n=10**6`? (*Hint*: Make sure to use a Numpy function to square all the elements!)\n\n::: {.callout-tip collapse=\"true\"}\n## Solution\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\ndef sum_sq_python(n):\n  numbers = range(0, n)\n  acc = 0\n  for i in numbers:\n    acc = acc + i**2\n  return acc\n\ndef sum_sq_numpy(n):\n  numbers = np.arange(0, n, dtype = np.int64)\n  return np.square(numbers).sum()\n\nfrom tinybench import benchmark, benchmark_env\nbench = benchmark(['sum_sq_python(10 ** 6)', 'sum_sq_numpy(10 ** 6)'], ntimes = 100, warmup = 10, g = globals())\nbench.plot()  \n```\n\n::: {.cell-output .cell-output-display}\n![](01-scipy-numpy_files/figure-html/cell-14-output-1.png){width=662 height=470}\n:::\n:::\n\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nbench.means['sum_sq_python'] / bench.means['sum_sq_numpy']\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\n44.68929493903305\n```\n:::\n:::\n\n\n:::\n\n#### Exercise 3\nRecall that the sample variance is defined as $\\sum (x_i - \\overline{x})^2 / (n-1)$, where $\\overline{x}$ is the sample mean and $n$ is the number of observations. Compare a Numpy-free implantation to the `var` method of `Numpy` (using the optional argument `ddof = 1`.), on the numbers from `1 .. 10 ** 5`, but this time, let `dtype = float64`. Be sure to check that your functions return the same result!\n\n(*Note*: You algorithm and `Numpy` might give different results for very large `n`. This is due to a phenomenon called [numerical instability](https://en.wikipedia.org/wiki/Numerical_stability), which we ignore in this course.)\n\n::: {.callout-tip collapse=\"true\"}\n## Solution\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\ndef var_python(n):\n  numbers = range(0, n)\n  mean = sum(numbers) / n\n  return sum([(x - mean) ** 2 for x in numbers]) / (n - 1)\n\ndef var_numpy(n):\n  numbers = np.arange(0, n, dtype = np.float64)\n  return numbers.var(ddof = 1)\n```\n:::\n\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nvar_numpy(10**5)\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\n833341666.6666666\n```\n:::\n:::\n\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nvar_python(10**5)\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\n833341666.6666666\n```\n:::\n:::\n\n\n:::\n### Numpy exercises\n\n#### Exercise 1\nHow do you do the following in Numpy? Make sure to make your own example in Python!\n    1. Make an identity matrix with `n` rows?\n    2. Make a matrix consisting of $0$s only?\n    3. Calculate the empirical mean of a vector? \n    4. Calculate the standard deviation of a vector normalized so that the variance is unbiased? (*Hint:* Read the Numpy documentation to find out what I mean!) Which of these do you think we are most interested in in this course?\n    5. Calculate \"cumulative sum\" operation on a vector `x`? (This operation creates a new vector `y` whose first element is `x[0]`, second `x[0] + x[1]`, etc.)\n    6. Take the element-wise logarithm of a matrix?\n\n#### Exercise 2\nDo this [Codewars exercise](https://www.codewars.com/kata/52fba2a9adcd10b34300094c) using Numpy indexing, i.e., not the built-in function `transpose`. You need to register at Codewars to do this exercise. In this and other Codewars problems, you can click the \"Unlock solutions\" button for solutions.\n\n#### Exercise 3\nDo the [following exercise](https://www.codewars.com/kata/568ff914fc7a40a18500005c/train/python), both with and without Numpy. (*Hint*: Use the `round` method to round the Numpy arrays. Remember to convert between `list` and `array` types!) \n\n#### Exercise 4\nDo the [following exercise](https://www.codewars.com/kata/57102bbfd860a3369300089c/train/python), both with and without Numpy. \n\n#### Exercise 5\nThe Github repo [Numpy-100](https://github.com/rougier/numpy-100) contains 100 Numpy exercises of variable difficulty. The Github page also includes hints and solutions. You can read the 100 problems [here](https://hackmd.io/@JonasMoss/numpy-100). Do **exercises 1 - 11 in** this repo. There is no upper limit to how many of the `numpy-100` you should do, but I would recommend you do as many as you can find time for. (These exercises are pretty short!) The point is to [*grok*](https://www.vocabulary.com/dictionary/grok) Numpy. (*Hint:* Use the Numpy documentation, Google, StackExchange, and so on. Check the hints if you have to.)\n\n",
    "supporting": [
      "01-scipy-numpy_files"
    ],
    "filters": [],
    "includes": {}
  }
}