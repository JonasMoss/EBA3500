[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data analysis with Programming",
    "section": "",
    "text": "Introduction\nWelcome to the course Data Analysis with Programming. This page contains the curriculum, exercises, and additional information for the course. If you need to get in contact with me, please send an e-mail to jonas.moss@bi.no. I do not check It’s learning often.\nThe majority of our curriculum is covered by two books.\nDekking, F. M., Kraaikamp, C., Lopuhaä, H. P., & Meester, L. E. (2005). A Modern Introduction to Probability and Statistics. Springer London. https://doi.org/10.1007/1-84628-168-7\nYou should know this book from your previous course in probability. We will follow the book closely.\nJames, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). An Introduction to Statistical Learning. Springer US. https://doi.org/10.1007/978-1-0716-1418-1\nThis on is available online for free; its webpage is here. It is a classic, and you can expect other data scientists to know it well. It is a simplified version Elements of Statistical Learning by Hastie, Tibshirani and Friedman, the best known and most widely referenced book of machine learning. The ambitious student will read Elements of Statistical Learning in addition to Introduction to Statistical Learning, but it is a significantly more difficult book.\nBe warned that Dekking et. al covers no programming at all, and James et al. uses R instead of Python. This will not cause us much difficulty, as R and Python are very similar languages. Supplementary material about Python can be found in the sidebar.\nThis course follows no strict schedule, as it is based around video lectures. The topics along with reading materials and associated video lectures can be found on the bar to the left. You will also find exercises there.\nThis course is partly about programming. Students often find programming hard. Don’t expect to be able solve every exercise in 5 minutes! Solving programming exercises often take a long time, and you need to persevere.\nTo become a decent programmer it’s a good idea to\nDo not to spend an inordinate amount of time on an exercise before you check the solution. If you have spent 1 hour on an exercise and haven’t gotten anywhere, it might be smart to save yourself some time and look at the solution. As I said, you can always come back to it later.\nMoreover, be aware that programming is often extremely frustrating. It’s like talking to someone who just simply refuses to understand what you’re saying, no matter how many times you repeat yourself. It’s normal and expected to feel frustrated!\nThere are many tips online about learning to program, e.g., this collection of tips. But it mostly boils down to spending a lot of time solving problems.\nCurious how this site was made? It is written using Quarto books."
  },
  {
    "objectID": "index.html#do-the-work",
    "href": "index.html#do-the-work",
    "title": "Data analysis with Programming",
    "section": "Do the work!",
    "text": "Do the work!\nThis is not a relaxing course. The content is difficult, both in terms of concepts and skills required. Statistics has an unfair and completely untrue reputation as an easy subject. It is not. Those who claim statistics is easy do not know statistics.\nRemember that you are expected to work full days as a student. Since you take four courses and all of them, presumably, have approximately \\(2\\) hours of lectures, that leaves \\(8\\) hours of studying – on your own – each week. I expect you to spend at least \\(10\\) hours with this course per week. But keeping in mind that this course is both significantly more important and significantly harder than your other courses, so you might have to spend even more time on it."
  },
  {
    "objectID": "index.html#resources",
    "href": "index.html#resources",
    "title": "Data analysis with Programming",
    "section": "Resources",
    "text": "Resources\nYou should probably use other resources than the lecture videos, the books, and the exercises. That is not because these resources do not cover the curriculum. It is because there are 100s of ways to teach the curriculum, and just as many points of view on the difficult parts. You often need to spend significant amounts of time with a concept, looking at it from different angles, in order to finally grok it. I did this all the time as a student, and every successful data scientist I know does this.\nYou should search the internet for answers early on. Understanding what to search for is an extremely important skill for life in general, but especially for data science, programming, and statistics. The key sites to look at are\n\nStackOverflow The primary resource for programming questions. Often covers statistics and data science questions too. Do not be afraid to ask questions there. You might get mean-spirited answers though. (Just accept the mean-spirited answers and move on.)\nCrossValidated The most widely used statistics Q&A site. Most answers are trustworthy, but the answers are often of lower quality than the other pages, and sometimes wrong. Ignore answers that look iffy.\nMathematics Stack Exhcange You use this for math questions. Probably not that useful in this course, but it might come up.\n\nThere is no definite 1st course in Python curriculum, which is a big and somewhat unwieldy language. You might not have learned about classes (object-oriented Python) or list comprehensions, or maybe not dictionaries either. I will use these concepts without additional explanation. Hence I would strongly recommend you spend 4 hours or so getting reasonably familiar with object-oriented programming in Python. It is not strictly speaking necessary for this course, as you won’t be asked to write your own classes. But some understanding of classes, methods, and attributes will help you understand what’s going on, perhaps even to a great degree! A reasonable place to start would be the videos of freeCodeCamp."
  },
  {
    "objectID": "site/00-python-tips.html#professional-programming",
    "href": "site/00-python-tips.html#professional-programming",
    "title": "Python tips",
    "section": "Professional programming",
    "text": "Professional programming\n\nFollow the style guide PEP.\nUse automatic formatters. I would recommend black, as it doesn’t give you any options.\nDocument your functions using docstrings.\n\nFollow the Python conventions. You may also want to follow more detailed guidelines such as the Google style guide.\nAt some point you want to learn about type hints. These make your code easier to understand and debug.\n\nTry to look into testing frameworks.\nUse modules to organize your work.\nLearn to use Github (with their student pack). You want to use Github due to its versions control and since it allows you to collaborate easily.\n\n\nHow?\n\nYou should try to apply your recently learned knowledge as often as possible. Have an assignment to write a Python function? Format it using black, write a docstring for it, use typehints, put it into an appropriate module (such as an EBA3500 module), give it a proper name, and publish it on your Github page. You can also practice some of these skills using gamified sites such as Codewars.\nAnother option is to work on random small projects, clean them up, and publish them on Github. Perhaps together with some of your costudents?"
  },
  {
    "objectID": "site/00-python-tips.html#better-programming",
    "href": "site/00-python-tips.html#better-programming",
    "title": "Python tips",
    "section": "Better programming",
    "text": "Better programming\n\nObject-oriented programming and classes. The first priority is to learn about classes and object-oriented programming. Most Python libraries for statistics (statsmodels) and machine learning (scikit-learn, PyTorch, Keras) Python are built around classes.\nLearn the features of the language.\n\nMake sure you know the basic data structures of the language.\nSkim the standard library and become familiar with the, for us at least, most important parts; collections, itertools, (and, perhaps string). There are many exercises on e.g. Codewars (exercises ranked as 7kyu and 8kyu) that will help you with this.\nLearn more advanced language features, such as generators, the pattern matching operator match, context managers for handling files and connections (using the with statement), and nested list comprehensions.\nLearn about common pitfalls. For instance, be careful when removing elements from a list in a for loop, and be aware that functions can modify their input.\n\nAlgorithms and data structures. Algorithms and data structures are about understanding how much time and memory programs require. This is a big field, but some reasonable goals is to\n\nUnderstand the difference between \\(O(n)\\), \\(O(n^2)\\), and \\(O(n\\log n)\\) algorithms. In addition, understand what an exponential time algorithm is and why it’s important to avoid them as much as you can. Also learn about why the dictionary is far faster than a list when doing lookups.\nThe highly competetive US job interviews at top tech companies such as Facebook, Google, Apple, Microsoft and Amazon are based on algorithms and data structures. This has created an enormous market for algorithms and data structure resources online, both free and paid. Algoexpert is an example of a partly free site with excellent resources.\nExercises at Codewars at rank about 5kyu and 6kyu cover intermediate algorithmic thinking.\n\n\n\nHow?\nGetting good at programming requires time, hard work, and perseverance. First, deliberate practice: You need to practice consistently and for non-trivial amounts of time, e.g. 30 minutes per day. You might even want to join the 100DaysOfCode challenge! Second, do more than required on assignments. Play around! Perhaps your assignment could be solved with sets instead of lists? Try it! Finally, read and try to answer Stack Overflow questions."
  },
  {
    "objectID": "site/01-scipy-numpy.html#curriculum",
    "href": "site/01-scipy-numpy.html#curriculum",
    "title": "1  Introduction to Numpy",
    "section": "1.1 Curriculum",
    "text": "1.1 Curriculum\n\nNumpy for absolute beginners\nThe notes on this webpage.\n\n\n1.1.1 Numpy\nI sometimes write that you should familiarize yourself with the documentation. This means that you should: 1. Fire up an instance of Visual Studio Code (recommended), Jupyter Notebook, or your prefered way to write Python. 2. Go to the supplied links and actively read them. You can’t just print out the documents and read them in the shade of a tree. You should make an hypothesis about how a snippet of code works, copy the Python code to your editor, and then modify it to check if your hypothesis is true.\n\n\n1.1.2 The speed of Numpy\nPython is very slow language. So slow, in fact, that most optimizations in Python is about moving as many computations as possible to Numpy.\nThe following function sums up all numbers from \\(1..n\\) in vanilla Python.\n\ndef sum_python(n):\n  numbers = range(0, n)\n  acc = 0\n  for i in numbers:\n    acc = acc + i\n  return acc\n\nThe function below uses Numpy for the same task.\n\nimport numpy as np\ndef sum_numpy(n):\n  numbers = np.arange(0, n, dtype = np.int64)\n  return numbers.sum()\n\nBoth functions return the same value.\n\nsum_python(10 ** 6)\n\n499999500000\n\n\n\nsum_numpy(10 ** 6)\n\n499999500000\n\n\nThe Numpy code is arguably easier to read. There is no doubt what the .sum method does.\nWe use the dtype = np.int64 argument in the np.arange function. This makes int64 the data type of the resulting Numpy array. These are 64 bits (signed) integers, but the standard is 32 bits integer. The difference between these lie in their maximum and minimum values. The maximal value of a 64 bits integer is 9,223,372,036,854,775,807, but the maximal value of an i32 is merely 2,147,483,647. You have to manually specify i64 when dealing with big integers in Numpy, but you do not need to do that in Python, as it can use integers of arbitrary size, at the cost of speed. You can always find the data type of a Numpy object using the .dtype method, e.g.,\n\nx = np.arange(0, 10)\nx.dtype\n\ndtype('int32')\n\n\nWe compare the execution speed of these functions using the benchmark function from the tinybench package. As always, type help(benchmark) in a Python interpreter to get help for the function. Below, we sample ntimes = 10 and use a warm up of 10 (to get the processor running). The g argument tells benchmark where to find the functions in the list, and the argument globals() tells it to look at the top level.\n\nfrom tinybench import benchmark, benchmark_env\nbench = benchmark(['sum_python(10 ** 6)', 'sum_numpy(10 ** 6)'], ntimes = 100, warmup = 10, g = globals())\nbench.plot()\n\n\n\n\nThe Numpy version is much faster. To pinpoint by exactly how much, we need to look at the mean execution times.\n\nbench.means\nbench.means['sum_python'] / bench.means['sum_numpy']\n\n10.571063624202676\n\n\nThe Numpy implementation is roughly \\(10\\) times faster. One can expect speedups even larger than this in more complex applications."
  },
  {
    "objectID": "site/01-scipy-numpy.html#exercises",
    "href": "site/01-scipy-numpy.html#exercises",
    "title": "1  Introduction to Numpy",
    "section": "1.2 Exercises",
    "text": "1.2 Exercises\n\n1.2.1 Data types\n\n1.2.1.1 Exercise 1\nFigure out the answer the following questions, using e.g. the Numpy documentation. (Look up the functions iinfo).\n\nWhat is the minimal value of a 32 bit integer in Numpy?\nWhat is the minimal value of a 64 bit integer in Numpy?\nIs there an integer type even larger than int64, provided you restrict yourself to non-negative numbers, i.e., unsigned integers?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe first two questions can be answered by\n\nnp.iinfo(np.int32)\n\niinfo(min=-2147483648, max=2147483647, dtype=int32)\n\n\n\nnp.iinfo(np.int64)\n\niinfo(min=-9223372036854775808, max=9223372036854775807, dtype=int64)\n\n\nFor the last question: Yes, the unsigned integers uint64 are larger.\n\nnp.iinfo(np.uint64)\n\niinfo(min=0, max=18446744073709551615, dtype=uint64)\n\n\n\n\n\n\n\n1.2.1.2 Exercise 2\nDecimal numbers in computer science are called floats, or floating point numbers. (Look up the functions finfo).\n\nWhat types of floats are available in Numpy?\nWhat is the default float type when using linspace?\nWhat are the maximal and minimal values of these float types?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nWe have np.float16, np.float32 and np.float64.\nUsing np.linspace(0, 1, 4).dtype we find that float64 is the default data type.\nWe can read that from the results below:\n\n\nnp.finfo(np.float64)\n\nfinfo(resolution=1e-15, min=-1.7976931348623157e+308, max=1.7976931348623157e+308, dtype=float64)\n\n\n\n\n\n\n\n\n1.2.2 Benchmarking and Numpy\n\n1.2.2.1 Exercise 1\nPython implements a method sum that sums every member of an iterable such as list. Implement a function sum_python2 that uses sum instead of a for-loop, but does not use Numpy. Compare its performance to sum_python above. What do you see?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndef sum_python2(n):\n  numbers = range(0, n)\n  return sum(numbers)\n\nfrom tinybench import benchmark, benchmark_env\nbench = benchmark(['sum_python(10 ** 6)', 'sum_python2(10 ** 6)', 'sum_numpy(10 ** 6)'], ntimes = 100, warmup = 10, g = globals())\nbench.plot()  \n\n\n\n\n\n\n\n\n\n1.2.2.2 Exercise 2\nWrite a function that squares and sums the numbers from 1 to n, one in Numpy and one in pure Python. Roughly how much faster is the Numpy implementation than the Python implementation when using n=1000, n=10000, or n=10**6? (Hint: Make sure to use a Numpy function to square all the elements!)\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndef sum_sq_python(n):\n  numbers = range(0, n)\n  acc = 0\n  for i in numbers:\n    acc = acc + i**2\n  return acc\n\ndef sum_sq_numpy(n):\n  numbers = np.arange(0, n, dtype = np.int64)\n  return np.square(numbers).sum()\n\nfrom tinybench import benchmark, benchmark_env\nbench = benchmark(['sum_sq_python(10 ** 6)', 'sum_sq_numpy(10 ** 6)'], ntimes = 100, warmup = 10, g = globals())\nbench.plot()  \n\n\n\n\n\nbench.means['sum_sq_python'] / bench.means['sum_sq_numpy']\n\n44.68929493903305\n\n\n\n\n\n\n\n1.2.2.3 Exercise 3\nRecall that the sample variance is defined as \\(\\sum (x_i - \\overline{x})^2 / (n-1)\\), where \\(\\overline{x}\\) is the sample mean and \\(n\\) is the number of observations. Compare a Numpy-free implantation to the var method of Numpy (using the optional argument ddof = 1.), on the numbers from 1 .. 10 ** 5, but this time, let dtype = float64. Be sure to check that your functions return the same result!\n(Note: You algorithm and Numpy might give different results for very large n. This is due to a phenomenon called numerical instability, which we ignore in this course.)\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndef var_python(n):\n  numbers = range(0, n)\n  mean = sum(numbers) / n\n  return sum([(x - mean) ** 2 for x in numbers]) / (n - 1)\n\ndef var_numpy(n):\n  numbers = np.arange(0, n, dtype = np.float64)\n  return numbers.var(ddof = 1)\n\n\nvar_numpy(10**5)\n\n833341666.6666666\n\n\n\nvar_python(10**5)\n\n833341666.6666666\n\n\n\n\n\n\n\n\n1.2.3 Numpy exercises\n\n1.2.3.1 Exercise 1\nHow do you do the following in Numpy? Make sure to make your own example in Python! 1. Make an identity matrix with n rows? 2. Make a matrix consisting of \\(0\\)s only? 3. Calculate the empirical mean of a vector? 4. Calculate the standard deviation of a vector normalized so that the variance is unbiased? (Hint: Read the Numpy documentation to find out what I mean!) Which of these do you think we are most interested in in this course? 5. Calculate “cumulative sum” operation on a vector x? (This operation creates a new vector y whose first element is x[0], second x[0] + x[1], etc.) 6. Take the element-wise logarithm of a matrix?\n\n\n1.2.3.2 Exercise 2\nDo this Codewars exercise using Numpy indexing, i.e., not the built-in function transpose. You need to register at Codewars to do this exercise. In this and other Codewars problems, you can click the “Unlock solutions” button for solutions.\n\n\n1.2.3.3 Exercise 3\nDo the following exercise, both with and without Numpy. (Hint: Use the round method to round the Numpy arrays. Remember to convert between list and array types!)\n\n\n1.2.3.4 Exercise 4\nDo the following exercise, both with and without Numpy.\n\n\n1.2.3.5 Exercise 5\nThe Github repo Numpy-100 contains 100 Numpy exercises of variable difficulty. The Github page also includes hints and solutions. You can read the 100 problems here. Do exercises 1 - 11 in this repo. There is no upper limit to how many of the numpy-100 you should do, but I would recommend you do as many as you can find time for. (These exercises are pretty short!) The point is to grok Numpy. (Hint: Use the Numpy documentation, Google, StackExchange, and so on. Check the hints if you have to.)"
  },
  {
    "objectID": "site/01-scipy-numpy.html#additional-resources",
    "href": "site/01-scipy-numpy.html#additional-resources",
    "title": "1  Introduction to Numpy",
    "section": "1.3 Additional resources",
    "text": "1.3 Additional resources"
  },
  {
    "objectID": "site/02-statistical-simulation.html#curriculum",
    "href": "site/02-statistical-simulation.html#curriculum",
    "title": "2  Statistical simulation and limit theorems",
    "section": "2.1 Curriculum",
    "text": "2.1 Curriculum\n\n2.1.1 Core readings\n\nDekking et al., Chapter 13: The law of large numbers\nDekking et al., Chapter 14: The central limit theorem\nThe notes below.\n(Optional)Dekking et al., Chapter 6: Simulations. Except Chapter 6.4 The single-server queue.\n\n\n\n2.1.2 Random number generators\n\nimport numpy as np\nimport scipy as sp\n\nWe start by defining an random number generator (rng). Computers do not usually generate truly random numbers. Instead they generate so-called pseudo-random numbers using methods such as the linear congruential generator. (It is possible to generate truly random numbers using the RDRAND instruction on x64 processors, but this feature is almost never used for various reasons.)\n\nrng = np.random.default_rng(seed = 313)\nrng\n\nGenerator(PCG64) at 0x14BFA36FCA0\n\n\nAs you can see, the object rng is a Generator(PCG64), i.e., a random number generator.\nGenerator objects have methods, such as uniform and normal, that may be used to generate random values.\n\nrng.uniform(0, 1, size = 10)\n\narray([0.63182242, 0.46427464, 0.77927765, 0.40253182, 0.61196237,\n       0.32392294, 0.10567386, 0.68671495, 0.01786417, 0.60813899])\n\n\nThis code generates a column vector of ten elements randomly sampled from the uniform distribution on \\([0,1]\\). The size argument is a Numpy dimension, hence you can write:\n\nrng.uniform(0, 1, size = (2, 10))\n\narray([[0.77322932, 0.23260444, 0.56660324, 0.96823875, 0.93026402,\n        0.71578432, 0.29358623, 0.53439132, 0.81535993, 0.42267216],\n       [0.96857697, 0.96626312, 0.24506702, 0.44363894, 0.45995697,\n        0.86179148, 0.45618709, 0.90139015, 0.51322552, 0.93442797]])\n\n\nThis is an array with \\(2\\) rows and \\(10\\) columns.\nOur generator rng was defined using the argument seed = 313. This is used for reproducibility. If you run the same code twice with the same seed, the result is going to be the same.\n\nrng1 = np.random.default_rng(seed = 313)\nrng2 = np.random.default_rng(seed = 313)\n(rng1.uniform(0, 1, size = (2, 2)), rng2.uniform(0, 1, size = (2, 2)))\n\n(array([[0.63182242, 0.46427464],\n        [0.77927765, 0.40253182]]),\n array([[0.63182242, 0.46427464],\n        [0.77927765, 0.40253182]]))\n\n\nBut the results will not be the same if we do not provide the seed!\n\nrng1 = np.random.default_rng()\nrng2 = np.random.default_rng()\n(rng1.uniform(0, 1, size = (2, 2)), rng2.uniform(0, 1, size = (2, 2)))\n\n(array([[0.7517041 , 0.14098333],\n        [0.43197008, 0.90082144]]),\n array([[0.97025446, 0.64707406],\n        [0.68077437, 0.59009093]]))\n\n\nReproducibility is important in scientific applications, as the reader of your work can exactly reproduce your simulations on his own computer. It’s also relevant for our coursework, as it allows your teacher to automatically grade your submissions.\nThe first two arguments of rng.uniform specify the start point and end point of the interval we sample from.\n\nrng1 = np.random.default_rng(seed = 313)\nrng2 = np.random.default_rng(seed = 313)\nx = rng1.uniform(2, 5, size = (2, 2)) # starting at 2 and ending at 5,\ny = rng2.uniform(0, 1, size = (2, 2)) # starting at 0 and ending at 1.\n\n(x, 3*y + 2)\n\n(array([[3.89546727, 3.39282392],\n        [4.33783294, 3.20759547]]),\n array([[3.89546727, 3.39282392],\n        [4.33783294, 3.20759547]]))\n\n\nNow \\(x\\) and \\(y\\) are the same. This will always be the case.\n\n2.1.2.1 Quick exercise\nGenerate an array of uniformly distributed numbers on \\([1,5]\\) with \\(3\\) rows and \\(4\\) columns.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nx = rng1.uniform(2, 5, size = (3, 4))\nx\n\narray([[3.8358871 , 2.97176881, 2.31702157, 4.06014485],\n       [2.05359251, 3.82441698, 4.31968797, 2.69781331],\n       [3.69980971, 4.90471626, 4.79079206, 4.14735295]])\n\n\n\n\n\n\n\n\n2.1.3 Using distributions\nYou can generate normally distributed random values with mean mu and standard deviation sigma using rng.normal(mu, sigma, size). Again, the size argument tells numpy how many rows, columns and potentially more dimensions you want your array to have.\n\nx = rng1.normal(0, 1, 10000)\n\nLet’s verify that x is normally distributed by plotting its histogram.\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.histplot(x, stat = \"density\")\nplt.show()\nplt.clf()\n\n\n\n\n<Figure size 672x480 with 0 Axes>\n\n\nRecall the formula for the density of the normal distribution, \\[f(x;\\mu,\\sigma) = \\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp{\\lbrack-\\frac{1}{2}(x-\\mu)^2}\\rbrack.\\] To verify that the histogram is normal, we can overlay the density of a normal on top of it.\n\ny = np.linspace(-5, 5, 1000)\ndef normpdf(x, mu = 0, sigma = 1):\n  return np.exp(-(x - mu) ** 2 * 0.5) * 1/(np.sqrt(2 * np.pi) * sigma)\n\nsns.histplot(x, stat = \"density\")\nplt.plot(y, normpdf(y), color = \"red\")\nplt.show()\n\n\n\n\nThe Generator object supports random sampling from many other distributions too. See the documenation for a complete list. The examples below are especially important.\n\n\n\n\n\n\n\nFunction\nDistribution\n\n\n\n\nintegers\nRandom integers from low (inclusive) to high (exclusive).\n\n\nchoice\nSample from an array with or without replacement.\n\n\nuniform\nUniformly distributed numbers.\n\n\nrandom\nUniformly distributed numbers on [0,1].\n\n\nnormal\nNormally distributed numbers.\n\n\nstandard_normal\nNormally distributed numbers with mean 0 and standard deviation 1.\n\n\nexponential\nExponentially distributed numbers with scale parameter.\n\n\nstandard_exponential\nExponentially distributed numbers with scale parameter 1.\n\n\n\n\n2.1.3.1 Quick exercise\nSimulate \\(10,000\\) random variables from a standard exponential. Verify that the random variables were simulated from an exponential by overlaying the standard exponential density.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nx = rng1.standard_exponential(10000)\ny = np.linspace(0, 6, 1000)\nsns.histplot(x, stat = \"density\")\nplt.plot(y, np.exp(-y), color = \"red\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n2.1.4 Simulating dice throws\nRandom number generators are often used to calculate probabilities that are hard to calculate by hand. You might be able to calculate, say, what he probability of getting a sum equal to \\(7\\) is when throwing \\(2\\) dice. But what about the probability that the maximal value \\(6\\) or that the sum is \\(7\\)? This is also doable by hand, but it’s easier to do it by machine.\n\nrng = np.random.default_rng(seed = 313)\nthrows = rng.integers(1, 7, size = (10000, 2))\n# throws contaisn 10000 rows of two dice throws.\ntotals = throws.sum(axis = 1)\nmaxs = throws.max(axis = 1)\n(totals, maxs)\n\n(array([6, 5, 6, ..., 9, 8, 9], dtype=int64),\n array([4, 3, 5, ..., 6, 5, 6], dtype=int64))\n\n\nTo calculate our probability, we need either totals == 7 or maxs == 6. We can use vectorized “OR” using the Numpy function logical_or to calculate this.\n\nx = np.logical_or(totals == 7, maxs == 6)\nx\n\narray([False, False, False, ...,  True, False,  True])\n\n\nThen we can take their mean to figure out the probability.\n\nx.mean()\n\n0.4134\n\n\nThus the probability is approximately \\(0.41\\). (Observe that Numpy automatically interprets True as 1 and False as 0 when forced to interpret boolean values as integers.)\nIn practice, we would write all of this in one go, probably using a function.\n\ndef prob(rng, n_reps = 10000):\n  throws = rng.integers(1, 7, size = (10000, 2))\n  return np.logical_or(throws.sum(axis = 1) == 7, throws.max(axis = 1) == 6).mean()\n  \nprob(rng)\n\n0.422\n\n\nThe result of this simulation is slightly different from the last one. This is due to randomnes, pure and simple. As we have already generated values from our rng, we would have to reset it to get the same value as before.\n\nrng = np.random.default_rng(seed = 313)\nprob(rng)\n\n0.4134\n\n\n\n\n2.1.5 Complex simulation\nSuppose that \\(X_1,X_2,\\ldots,X_k\\) are \\(k\\) iid exponential variables with density \\(\\lambda e^{-\\lambda x}, \\lambda > 0\\). It has been claimed that the minimum of \\(k\\) such variables are exponentially distributed with parameter \\(k \\lambda\\), i.e., \\(\\min(X_1,X_2,\\ldots,X_k)\\) has density \\(\\lambda k e^{-\\lambda k x}\\). Let’s try to verify this using simulations.\n\nrng = np.random.default_rng(seed = 313)"
  },
  {
    "objectID": "site/02-statistical-simulation.html#exercises",
    "href": "site/02-statistical-simulation.html#exercises",
    "title": "2  Statistical simulation and limit theorems",
    "section": "2.2 Exercises",
    "text": "2.2 Exercises"
  },
  {
    "objectID": "site/02-statistical-simulation.html#additional-resources",
    "href": "site/02-statistical-simulation.html#additional-resources",
    "title": "2  Statistical simulation and limit theorems",
    "section": "2.3 Additional resources",
    "text": "2.3 Additional resources"
  },
  {
    "objectID": "site/03-exploratory-data-analysis.html#curriculum",
    "href": "site/03-exploratory-data-analysis.html#curriculum",
    "title": "3  Exploratory data analysis",
    "section": "3.1 Curriculum",
    "text": "3.1 Curriculum\n\n3.1.1 Core readings\n\nDekking et al., Chapter 15: Exploratory data analysis: graphical summaries\nDekking et al., Chapter 16: Exploratory data analysis: numerical summaries\n\n\n\n3.1.2 Python\n\n3.1.2.1 Using seaborn for graphical summaries\n\n\n3.1.2.2 Numpy and scipy for numerical summaries"
  },
  {
    "objectID": "site/03-exploratory-data-analysis.html#exercises",
    "href": "site/03-exploratory-data-analysis.html#exercises",
    "title": "3  Exploratory data analysis",
    "section": "3.2 Exercises",
    "text": "3.2 Exercises"
  },
  {
    "objectID": "site/03-exploratory-data-analysis.html#additional-resources",
    "href": "site/03-exploratory-data-analysis.html#additional-resources",
    "title": "3  Exploratory data analysis",
    "section": "3.3 Additional resources",
    "text": "3.3 Additional resources"
  },
  {
    "objectID": "site/04-statistical-models.html#curriculum",
    "href": "site/04-statistical-models.html#curriculum",
    "title": "4  Basic statistical models and the bootstrap",
    "section": "4.1 Curriculum",
    "text": "4.1 Curriculum\n\n4.1.1 Core readings\n\nDekking et al., Chapter 17: Basic statistical models, except Chapter 17.4. Ignore the paragraphs about the Poisson model.\nDekking et al., Chapter 18: The bootstrap\n\n\n\n4.1.2 Basic statistical model in Python\n\n\n4.1.3 Bootstrap in Python"
  },
  {
    "objectID": "site/04-statistical-models.html#exercises",
    "href": "site/04-statistical-models.html#exercises",
    "title": "4  Basic statistical models and the bootstrap",
    "section": "4.2 Exercises",
    "text": "4.2 Exercises"
  },
  {
    "objectID": "site/04-statistical-models.html#additional-resources",
    "href": "site/04-statistical-models.html#additional-resources",
    "title": "4  Basic statistical models and the bootstrap",
    "section": "4.3 Additional resources",
    "text": "4.3 Additional resources"
  },
  {
    "objectID": "site/05-unbiased-estimators-efficiency.html#curriculum",
    "href": "site/05-unbiased-estimators-efficiency.html#curriculum",
    "title": "5  Unbiased estimators and efficiency",
    "section": "5.1 Curriculum",
    "text": "5.1 Curriculum\n\n5.1.1 Core readings\n\nDekking et al., Chapter 19: Unbiased estimators\nDekking et al., Chapter 20: Efficiency and mean squared error"
  },
  {
    "objectID": "site/05-unbiased-estimators-efficiency.html#exercises",
    "href": "site/05-unbiased-estimators-efficiency.html#exercises",
    "title": "5  Unbiased estimators and efficiency",
    "section": "5.2 Exercises",
    "text": "5.2 Exercises"
  },
  {
    "objectID": "site/05-unbiased-estimators-efficiency.html#additional-resources",
    "href": "site/05-unbiased-estimators-efficiency.html#additional-resources",
    "title": "5  Unbiased estimators and efficiency",
    "section": "5.3 Additional resources",
    "text": "5.3 Additional resources"
  },
  {
    "objectID": "site/06-constructing-estimators.html#curriculum",
    "href": "site/06-constructing-estimators.html#curriculum",
    "title": "6  Constructing estimators",
    "section": "6.1 Curriculum",
    "text": "6.1 Curriculum\n\n6.1.1 Core readings\n\nDekking et al., Chapter 21: Maximum likelihood\nDekking et al., Chapter 22: The method of least squares"
  },
  {
    "objectID": "site/06-constructing-estimators.html#exercises",
    "href": "site/06-constructing-estimators.html#exercises",
    "title": "6  Constructing estimators",
    "section": "6.2 Exercises",
    "text": "6.2 Exercises"
  },
  {
    "objectID": "site/06-constructing-estimators.html#additional-resources",
    "href": "site/06-constructing-estimators.html#additional-resources",
    "title": "6  Constructing estimators",
    "section": "6.3 Additional resources",
    "text": "6.3 Additional resources"
  },
  {
    "objectID": "site/07-confidence-intervals.html#curriculum",
    "href": "site/07-confidence-intervals.html#curriculum",
    "title": "7  Confidence intervals",
    "section": "7.1 Curriculum",
    "text": "7.1 Curriculum\n\n7.1.1 Core readings\nDekking et al., Chapter 23: Confidence intervals for the mean\nDekking et al., Chapter 24: More on confidence intervals\n\n7.1.1.1 Scipy functions\n\nhttps://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html\nhttps://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.zscore.html\nhttps://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html\nhttps://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html"
  },
  {
    "objectID": "site/07-confidence-intervals.html#exercises",
    "href": "site/07-confidence-intervals.html#exercises",
    "title": "7  Confidence intervals",
    "section": "7.2 Exercises",
    "text": "7.2 Exercises\n\n7.2.1 Theory exercises\nDekking et al., Chapter 23: 23.1, 23.2, 23.3, 23.4, 23.6, 23.11, 23.12\n\n\n7.2.2 Python exercises\nSolve the following exercises using Python. In both exercises you are asked to construct a bootstrap interval using the provided data, but you should use the t-test too. Dekking et al., Chapter 23: 23.5(a,b), 23.9\nA1: Make your own custom function tinterval(data, alpha) that constructs a confidence interval for the mean with confidence level \\(1-\\alpha\\). Assume the data are normally distributed. A2: Make your own custom function bootinterval(data, alpha, rng) that constructs are bootstrap percentile confidence interval with confidence level \\(1-\\alpha\\) based on the random number generator \\(rng\\).\n\n\n7.2.3 Simulation exercises"
  },
  {
    "objectID": "site/07-confidence-intervals.html#additional-resources",
    "href": "site/07-confidence-intervals.html#additional-resources",
    "title": "7  Confidence intervals",
    "section": "7.3 Additional resources",
    "text": "7.3 Additional resources\nDekking et al., Chapter 24 covers confidence intervals for different quantities than the mean. This chapter is not part of the curriculum but is still worth reading."
  },
  {
    "objectID": "site/08-testing-hypotheses.html#curriculum",
    "href": "site/08-testing-hypotheses.html#curriculum",
    "title": "8  Testing hypotheses",
    "section": "8.1 Curriculum",
    "text": "8.1 Curriculum\n\nDekking et al., Chapter 25: Testing hypotheses: essentials\nDekking et al., Chapter 26: Testing hypotheses: elaboration ## Exercises"
  },
  {
    "objectID": "site/08-testing-hypotheses.html#additional-resources",
    "href": "site/08-testing-hypotheses.html#additional-resources",
    "title": "8  Testing hypotheses",
    "section": "8.2 Additional resources",
    "text": "8.2 Additional resources"
  },
  {
    "objectID": "site/09-testing-the-sample-mean.html#curriculum",
    "href": "site/09-testing-the-sample-mean.html#curriculum",
    "title": "9  Testing the sample mean",
    "section": "9.1 Curriculum",
    "text": "9.1 Curriculum\n\nDekking et al., Chapter 27: The t-test\nDekking et al., Chapter 28: Comparing two samples\nThe following article on AB testing."
  },
  {
    "objectID": "site/09-testing-the-sample-mean.html#exercises",
    "href": "site/09-testing-the-sample-mean.html#exercises",
    "title": "9  Testing the sample mean",
    "section": "9.2 Exercises",
    "text": "9.2 Exercises"
  },
  {
    "objectID": "site/09-testing-the-sample-mean.html#recommended-resources",
    "href": "site/09-testing-the-sample-mean.html#recommended-resources",
    "title": "9  Testing the sample mean",
    "section": "9.3 Recommended resources",
    "text": "9.3 Recommended resources"
  },
  {
    "objectID": "site/10-statistical-learning.html#curriculum",
    "href": "site/10-statistical-learning.html#curriculum",
    "title": "10  Statistical learning, machine learning, and statistics",
    "section": "10.1 Curriculum",
    "text": "10.1 Curriculum\n\nJames et al., Chapter 1: Introduction\nJames et al., Chapter 2: Statistical learning"
  },
  {
    "objectID": "site/10-statistical-learning.html#exercises",
    "href": "site/10-statistical-learning.html#exercises",
    "title": "10  Statistical learning, machine learning, and statistics",
    "section": "10.2 Exercises",
    "text": "10.2 Exercises"
  },
  {
    "objectID": "site/10-statistical-learning.html#recommended-resources",
    "href": "site/10-statistical-learning.html#recommended-resources",
    "title": "10  Statistical learning, machine learning, and statistics",
    "section": "10.3 Recommended resources",
    "text": "10.3 Recommended resources"
  },
  {
    "objectID": "site/11-basics-of-linear-regression.html#curriculum",
    "href": "site/11-basics-of-linear-regression.html#curriculum",
    "title": "11  Basics of multiple linear regression",
    "section": "11.1 Curriculum",
    "text": "11.1 Curriculum"
  },
  {
    "objectID": "site/11-basics-of-linear-regression.html#exercises",
    "href": "site/11-basics-of-linear-regression.html#exercises",
    "title": "11  Basics of multiple linear regression",
    "section": "11.2 Exercises",
    "text": "11.2 Exercises"
  },
  {
    "objectID": "site/11-basics-of-linear-regression.html#recommended-resources",
    "href": "site/11-basics-of-linear-regression.html#recommended-resources",
    "title": "11  Basics of multiple linear regression",
    "section": "11.3 Recommended resources",
    "text": "11.3 Recommended resources"
  },
  {
    "objectID": "site/12-inference-for-linear-regression.html#curriculum",
    "href": "site/12-inference-for-linear-regression.html#curriculum",
    "title": "12  Inference for multiple linear regression",
    "section": "12.1 Curriculum",
    "text": "12.1 Curriculum"
  },
  {
    "objectID": "site/12-inference-for-linear-regression.html#exercises",
    "href": "site/12-inference-for-linear-regression.html#exercises",
    "title": "12  Inference for multiple linear regression",
    "section": "12.2 Exercises",
    "text": "12.2 Exercises"
  },
  {
    "objectID": "site/12-inference-for-linear-regression.html#solutions-to-exercises",
    "href": "site/12-inference-for-linear-regression.html#solutions-to-exercises",
    "title": "12  Inference for multiple linear regression",
    "section": "12.3 Solutions to exercises",
    "text": "12.3 Solutions to exercises"
  },
  {
    "objectID": "site/12-inference-for-linear-regression.html#recommended-resources",
    "href": "site/12-inference-for-linear-regression.html#recommended-resources",
    "title": "12  Inference for multiple linear regression",
    "section": "12.4 Recommended resources",
    "text": "12.4 Recommended resources"
  },
  {
    "objectID": "site/14-binary-regression.html#curriculum",
    "href": "site/14-binary-regression.html#curriculum",
    "title": "13  Binary regression",
    "section": "13.1 Curriculum",
    "text": "13.1 Curriculum\n\nJames et al., Chapters 4.1 - 4.3, 4.7.1 - 4.7.7"
  },
  {
    "objectID": "site/14-binary-regression.html#exercises",
    "href": "site/14-binary-regression.html#exercises",
    "title": "13  Binary regression",
    "section": "13.2 Exercises",
    "text": "13.2 Exercises"
  },
  {
    "objectID": "site/14-binary-regression.html#recommended-resources",
    "href": "site/14-binary-regression.html#recommended-resources",
    "title": "13  Binary regression",
    "section": "13.3 Recommended resources",
    "text": "13.3 Recommended resources"
  }
]