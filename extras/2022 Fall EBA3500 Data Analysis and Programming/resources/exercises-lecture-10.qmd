---
title: "Exercises for Lecture 10"
subtitle: "EBA3500 Data analysis with programming"
author: "Jonas Moss"
institute: BI Norwegian Business School </br> Department of Data Science and Analytics
format: 
    html:
      self-contained: true
editor: visual
execute:
  cache: true
  enabled: true
  output: true
  freeze: auto
jupyter: python3
number-sections: true
---

## Review exercises

1.  Mention three methods you can use to compare linear regression models. Can all of them be used for binary regression models?
2.  What is a confusion matrix and what is it used for?
3.  When would you ever use a robust regression model?
4.  What is a QQ-plot good for?

## Model selection

### Using the AIC

We'll take a look the [Indian Liver Data](https://www.kaggle.com/datasets/uciml/indian-liver-patient-records), available at the Github page. The aptly named `Dataset` column is `1` if the row corresponds to a liver patient and `2` otherwise. This exercise is inspired by [this page](https://rpubs.com/arashmsda/Logistic_Regression_Stepwise_AIC).

```{python}
import numpy as np
import pandas as pd
liver = pd.read_csv("indian_liver_patient.csv")
```

1.  Fix the name of the `Dataset` column to something more informative and change its values from `1` and `2` to something better. (**Hint:** These are binary variables and we want to predict the value of `Dataset`!)
2.  Try out at least five different logistic models predicting `Dataset` from the other variables.
3.  Interpret the regression coefficients.
4.  Do the same exercise, but this time only for male patients. Do you conclude the same?
5.  Run the same models as in (2) and (4), but this time with the Probit and Cauchit link functions. Do they work better?

## Model fit

### QQ plots

1.  Simulate $n = 1000$ observations from a regression model with $\beta_0 = 1,\beta_1=0,\beta_2=2$ and $\sigma = 2$, but with the errors distributed according to the Cauchy distribution. The covariates can be simulated however you wish.
2.  Using the simulated data, fit an `ols` model and extract the residuals. Make a QQ plot. Does it look ok?
3.  Replicate the simulation in exercise (1) $N=10,000$ times. For each iteration, extract the $p$-value for $\beta_1$. Interpret your findings.

## Robust regression

### Animals

We study the `animals` data from `robustbase`.

> A data frame with average brain and body weights for 62 species of land mammals and three others.

```{python}
import rdatasets as rd
telef = rd.data("Robustbase", "Animals2")
```

1.  Plot `body` on the \$x\$-axis and brain on the $y$-axis. Try out transformations to make the relationsship roughly linear. (**Hint:** What are the most important transformations to try out?)
2.  The plot contains some *outliers*, i.e., data points that differs significantly from other observations. What to methods can you use to handle such outliers?
3.  Fit appropriate models using both strategies of question (2).

### A multitude of loss functions

The documentation of [\`rlm\`](https://www.statsmodels.org/stable/rlm.html) mentions several different norms. We have used the Huber norm, but there are several alternatives.

```{python}
import rdatasets as rd
telef = rd.data("Robustbase", "telef")
```

1.  Fit an `rlm` using the `telef` data with three different norms of your choice.
2.  Plot the data and make a choice between the models.
