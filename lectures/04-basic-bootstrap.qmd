---
title: "Basic statistical models and bootstrap"
author: "Jonas Moss"
---

## 17.1 Random samples and statistical models

**Definition:** Random samples

**Definition.** Statistical model 

**Which model fits our dataset best?**

## 17.2 Distribution features and sample statistics

**Empirical distribution function.** (ECDF.)
1. Recall that the distribution function $F = P(X\leq x)$. This function contains all information about the distribution of a random variable.

2. 

**Histograms.**
**Kernel density estimators.**

## 17.3 Estimating features of true distributions

## 18.1 The bootstrap principle
* The empirical mean is $\hat{\mu}$, but this doesn't equal the true expectation.
* How uncertain are we about this estimate? Ideally, we would like to know the exact distribution of it. Then we can calculate e.g., the mean and variance of it. This gives us information about how much we can trust our estimator.
* Example: Think about the heights of Norwegian males. What is their true mean height? Suppose you know only $10$ of them, with heights $x_1, x_2, \ldots, x_{10}$. Clearly, the mean you calculate is not equal to the true mean! But how "far off" do you expect to be?
* These questions are hard, since we do not know the true underlying model. 
* This is where the bootstrap principle enters the picture. You "pretend" that your sample is the true distribution.
* We don't know the distribution of our estimator.

## 18.2 The empirical bootstrap

* **Bootstrapping the mean.** The distance between the true sampling distribution and the bootstrap sampling distribution goes to $0$. Let's investigate what that means in Python. (This does not always hold, but is true sufficiently often to be important. If in doubt, *run a simulation to check!*)

* The distribution of $\mu^\star - \hat{\mu}$ is in principle possible to compute, but there are $n^n$ different combinations. If $n$ is really small, it is possible to enumerate all of them, but bootstrapping virtually always refers to simulations instead. (When $n = 10$, $n^n = 10,000,000,000$, already way too much.)

```{python}
import numpy as np
import pandas as pd
of = pd.read_csv("old-faithful.tsv", sep = "\t")
of["seconds"] = of["eruptions"] * 60
```

```{python}
of["seconds"].mean()
```
```{python}
import matplotlib.pyplot as plt
plt.hist(of["seconds"])
plt.show()
```
```{python}
seconds = of["seconds"].to_numpy()
mean = of["seconds"].mean()
rng = np.random.default_rng(313)
mean_star = rng.choice(seconds, [1000, seconds.size], replace = True).mean(axis = 1)
mean_star.size
```
```{python}
plt.clf()
plt.hist(mean_star - mean)
plt.show()
```

## 18.3 The parametric bootstrap

Sometimes you know something about the data-generating process. For instance, you might now the data-generating process is exponential. In this case you can use the *parametric bootstrap*. The parametric bootstrap performs better than the non-parametric bootstrap, but is only valid as long as you know the true distribution.

Simulation is similar. But instead simulating from the data itself, you simulate from the known distribution using your estimated parameters. 